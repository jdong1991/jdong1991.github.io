---
layout:     post
title:      Python爬虫之腾讯漫画
subtitle:   
date:       2019-05-20
author:     JD
header-img: img/post-jd-spider2.jpg
catalog: true
tags:
    - spider
    - requests
    - BeautifulSoup
---

## 简述

这是个爬虫的实战，爬取的是[腾讯漫画](https://ac.qq.com/Comic/all/search/hot/vip/1/page/1)。

爬取的内容有全部腾讯漫画的信息，主要以下三点

- 漫画基本信息，包括作者、人气、封面地址、收藏数、是否连载、漫画简述等
- 漫画章节名称
- 漫画章节的全部图片

我的Python版本是`Python 3.7.3`，主要使用的Python库为`requests`和`BeautifulSoup`。

## 漫画信息

打开腾讯漫画的目录，发现每页有12部漫画

![](http://wx4.sinaimg.cn/mw690/006F1DTzgy1g37ow20mxvj30zt0i048v.jpg)

现在需要做的是采集每部漫画的名称和url。可以看代码，发现`class="ret-search-result"`下面有12个`<li>`标签，正好记录着12部漫画的信息。`class="ret-works-info"`下`<a>`标签的`title`和`href`就是我们所需要的漫画名称和url。

![](http://wx3.sinaimg.cn/mw690/006F1DTzgy1g37ow4u8f7j30mb0arwgr.jpg)

Python代码实现

    import requests
    from bs4 import BeautifulSoup
    
    page_url = "https://ac.qq.com/Comic/all/search/hot/vip/1/page/1"
    headers = {
        'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36'
                       ' (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36')
    }
    r = requests.get(page_url, headers=headers)
    html = BeautifulSoup(r.text, 'lxml')
    ret_search_result = html.find(attrs={'class': 'ret-search-result'})
    ret_works_infos = ret_search_result.find_all(attrs={'class': 'ret-works-info'})
    page_mhs = [[info.a.get('title'),
                 'https://ac.qq.com' + info.a.get('href')] for info in ret_works_infos]
    page_mhs

输出如下图

![](http://wx2.sinaimg.cn/mw690/006F1DTzgy1g380pbsvevj30gu06twem.jpg)

选`尸兄（我叫白小飞）`来作为我们爬取漫画信息的案例。从上面采集到的信息可以知道它的url是`https://ac.qq.com/Comic/comicInfo/id/17114`。我们进入这个页面，可以发现漫画的**作者**、**人气**、**封面地址**、**收藏数**、**是否连载**、**漫画简述**。

![](http://wx3.sinaimg.cn/mw690/006F1DTzgy1g37ow7cngxj30rn0h444d.jpg)

从网页就可以很容易看出我们要采集的内容。

    mh_url = "https://ac.qq.com/Comic/comicInfo/id/17114"
    r = requests.get(mh_url, headers=headers)
    html = BeautifulSoup(r.text, 'lxml')
    works_intro = html.find(attrs={'class': 'works-intro'})

    tg_spic = works_intro.img.get('src')
    typelianzai = works_intro.find(attrs={'works-intro-status'}).text  # 连载中

    digi = works_intro.find(attrs={'class': 'works-intro-digi'}).find_all('span')
    author = ' '.join(digi[0].em.text.split())  # 七度魚 图：七度魚 文：七度魚
    hots = digi[1].em.text  # 227.7亿
    collect = digi[2].em.text  # 2922012

    short = works_intro.find(attrs={'class': 'works-intro-short'})
    intro = ''.join(short.text.split())  # 即将毁灭的世界......每周更新...

## 漫画章节

全部章节名、url

## 章节图片

图片url