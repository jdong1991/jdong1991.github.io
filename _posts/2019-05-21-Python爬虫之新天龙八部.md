---
layout:     post
title:      Python爬虫之新天龙八部
subtitle:   
date:       2019-05-21
author:     JD
header-img: img/post-jd-spider3.jpg
catalog: true
tags:
    - spider
    - requests
    - BeautifulSoup
---

## 背景

新天龙八部已经是十二年的老游戏，但我对它的热情不减当年。不过，游戏内的人已经走了一批又一批，游戏账号在一批批人的打造中加强了许多。这里主要是爬取全部服务器排行前50的角色装备评分，并做一个简单的分析。

## 排行榜

它的[排行榜页面](http://twjh.changyou.com/html/paihang/zd.shtml)也比较特别。可以看它源代码。

![](http://wx4.sinaimg.cn/mw690/006F1DTzgy1g3c4luam1cj30j90di3yp.jpg)

但是渲染后，可以看到

![](http://wx3.sinaimg.cn/mw690/006F1DTzgy1g3c4lrkyg9j30j20e4wf5.jpg)

这说明，它是异步的，我们需要找到传输给前端的选项文件。

依旧是打开`Chrome`，进入排行榜页面，按下`F12`，点击`Network`，选择`XHR`。重新刷新页面，会发现

![](http://wx4.sinaimg.cn/mw690/006F1DTzgy1g3c4lxr1ksj30l40csjsf.jpg)

看到`srvlist.txt`文件，里面有乱码，但是看格式貌似就是我们想要的。

好的，转下编码看下，发现正是所需`option`信息。

首先获取`srvlist.txt`文件。

![](http://wx4.sinaimg.cn/mw690/006F1DTzgy1g3c4qviyuzj30km0br3z8.jpg)

发现`Request URL`有记录获取地址

    import requests
    import pandas as pd
    
    srvlist_url = "http://twjh.changyou.com/html/tldata/srvlist.txt"
    headers = {
                'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36'
                               ' (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36')
    }
    r = requests.get(srvlist_url, headers=headers)
    r.encoding = 'utf-8'
    sers = r.text
    df = pd.DataFrame([ser.split(',') for ser in sers.split('\n')[:-1]],
                      columns=['daqu', 'qu', 'id'])
    df.head()

代码输出

||daqu|qu|id|
|:-|:-|:-|-:|
|0|东部电信|九阴真经|38|
|1|东部电信|玉女心经|154|
|2|东部电信|北冥神功|65|
|3|东部电信|雁翎枪|65|
|4|东部电信|七伤拳|9140|

找到每个选项后，发现下面展示的top50其实是嵌入的，使用`iframe`框架。

在属性`src`中，只需改变**id**就可以得到不同的服务器的排名，比如下图中的`1053`。

![](http://wx4.sinaimg.cn/mw690/006F1DTzgy1g3c4m006kwj30x80gsdi2.jpg)

    df.id.size  # 761
    df.id.unique().size  # 82
    df.id.unique()

    # array(['38', '154', '65', '9140', '172', '1010', '155', '47', '149',
             '2020', '1015', '3145', '1161', '162', '1191', '188', '182', '68',
             '1171', '2021', '191', '209', '198', '3048', '3144', '137', '168',
             '2202', '3081', '2201', '3016', '3079', '3085', '3125', '3128',
             '5024', '3200', '3202', '5057', '5016', '2082', '101', '22',
             '1138', '1053', '118', '2093', '111', '4036', '85', '134', '1043',
             '1042', '14', '3192', '3161', '4025', '5038', '5013', '5060',
             '5065', '5072', '5068', '5069', '5076', '5075', '5083', '5088',
             '5089', '5090', '5091', '5092', '5093', '5074', '5084', '5087',
             '5096', '5097', '5094', '5095', '9031', '9015'], dtype=object)

这十二年，居然开了761个区，搜狐真的很疯狂。

这么多区，也掩盖不了这游戏的没落，通过不断的合区，只剩下82个区。为什么合区，玩过网游都知道，就是因为区里人太少，要节约成本增加区里的活跃度，就开始合区！

把合区信息存到数据库中，并且以`id`为主键，将合并区的名称拼接起来。

    data_qu = (df.groupby('id')['qu']
                 .apply(lambda x: ','.join(x.values))
                 .reset_index())
    data_qu.columns = 'qu_id','qu_name'
    data_qu.to_sql('tlbb_qu', con=conn,
                   if_exists='append', index=False)

数据库中展示成

![](http://wx2.sinaimg.cn/mw690/006F1DTzgy1g3cny0abm2j30sj0803zi.jpg)

然后，就该爬取`iframe`里的内容，选择`id=38`。

![](http://wx2.sinaimg.cn/mw690/006F1DTzgy1g3c4m2aipnj30qm0j4t9x.jpg)

这里面我们需要爬取每一个角色的信息，包括`排名`、`装备评分`、`等级`、`门派`、`所属帮派`。

![](http://wx2.sinaimg.cn/mw690/006F1DTzgy1g3c4mgdr6qj30cw08mdfu.jpg)

在`<tr>`里有5个`<td>`，就包含所要信息。

代码撸起来

    qu_id = '38'
    qu_ph_url = f"http://www.tl.changyou.com/tlbbrank/{qu_id}/top50zhanli.html"
    ph_r = requests.get(qu_ph_url, headers=headers)
    ph = BeautifulSoup(ph_r.content.decode('ANSI').replace('&nbsp;',''), 'lxml')
    trs = ph.findAll('tr')[1:]
    df_qu = pd.DataFrame([[td.text for td in tr.findAll('td')] for tr in trs],
                 columns=['ph', 'player_name', 'score', 'grade', 'school', 'gang'])
    df_qu['qu_id'] = qu_id
    df_qu.head()

代码输出

||ph|player_name|score|grade|school|gang|qu_id|
|-:|-:|-:|-:|-:|-:|-:|-:|
|0|1|﹡﹒芝芝芒芒|1309672|119|逍遥|水泊梁山|38|
|1|2|龍戰メ粱山|1046449|119|逍遥|水泊梁山|38|
|2|3|龍戰メ乐小雨|985207|119|唐门|水泊梁山|38|
|3|4|Moon°﹎欣子|827651|119|天山|月光下的光芒|38|
|4|5|ゞ冷锋|794809|119|唐门|天缘山庄|38|

将数据存入mysql数据库，数据库对应的表示`tlbb_ph`。

    configs = {
                'host': '127.0.0.1',
                'user': 'root',
                'password': 'password',
                'database': 'testdb'
    }
    conn = create_engine("mysql+pymysql://{user}:{password}@{host}:3306/{database}".format(**configs))
    df_qu.to_sql('tlbb_ph', con=conn, if_exists='append', index=False)

这个区的爬取工作完成，数据也可以保存到文件。然后相同方式爬取剩下81个区。

## 排名分析

每个区的总装备评分   看最强10个区

百万评分个数top5

门派人数  门派平衡性



## 总结